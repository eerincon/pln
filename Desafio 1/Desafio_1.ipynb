{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq6j8LsYq1Dr"
      },
      "source": [
        "### Vectorización de texto y modelo de clasificación Naïve Bayes con el dataset 20 newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7cXR6CI30ry"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# 20newsgroups por ser un dataset clásico de NLP ya viene incluido y formateado\n",
        "# en sklearn\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD-pVDWV_rQc"
      },
      "source": [
        "## Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ech9qJaUo9vK"
      },
      "outputs": [],
      "source": [
        "# cargamos los datos (ya separados de forma predeterminada en train y test)\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxjSI7su_uWI"
      },
      "source": [
        "## Vectorización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-94VP0QYCzDn"
      },
      "outputs": [],
      "source": [
        "# instanciamos un vectorizador\n",
        "# ver diferentes parámetros de instanciación en la documentación de sklearn\n",
        "tfidfvect = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ftPlyanuak8n",
        "outputId": "2baac35c-b9d7-4504-d2f9-3bd3f2b20938"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 159
        }
      ],
      "source": [
        "# en el atributo `data` accedemos al texto\n",
        "newsgroups_train.data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zxcXV6aC_oL"
      },
      "outputs": [],
      "source": [
        "# con la interfaz habitual de sklearn podemos fitear el vectorizador\n",
        "# (obtener el vocabulario y calcular el vector IDF)\n",
        "# y transformar directamente los datos\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "# `X_train` la podemos denominar como la matriz documento-término"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Sv7TXbda41-",
        "outputId": "797be5ea-3c05-4a10-d75e-fccca55bcf3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n",
            "shape: (11314, 101631)\n",
            "cantidad de documentos: 11314\n",
            "tamaño del vocabulario (dimensionalidad de los vectores): 101631\n"
          ]
        }
      ],
      "source": [
        "# recordar que las vectorizaciones por conteos son esparsas\n",
        "# por ello sklearn convenientemente devuelve los vectores de documentos\n",
        "# como matrices esparsas\n",
        "print(type(X_train))\n",
        "print(f'shape: {X_train.shape}')\n",
        "print(f'cantidad de documentos: {X_train.shape[0]}')\n",
        "print(f'tamaño del vocabulario (dimensionalidad de los vectores): {X_train.shape[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgydNTZ2pAgR",
        "outputId": "b0d3360a-0188-41c2-cf05-87cc8cec5b34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25775"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ],
      "source": [
        "# una vez fiteado el vectorizador, podemos acceder a atributos como el vocabulario\n",
        "# aprendido. Es un diccionario que va de términos a índices.\n",
        "# El índice es la posición en el vector de documento.\n",
        "tfidfvect.vocabulary_['car']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnTSZuvyrTcP"
      },
      "outputs": [],
      "source": [
        "# es muy útil tener el diccionario opuesto que va de índices a términos\n",
        "idx2word = {v: k for k,v in tfidfvect.vocabulary_.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swa-AgWrMSHM",
        "outputId": "fa49e69f-5c65-4720-a9ca-1c3f0e485323"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ],
      "source": [
        "# en `y_train` guardamos los targets que son enteros\n",
        "y_train = newsgroups_train.target\n",
        "y_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je5kxvQMDLvf",
        "outputId": "bdc7ef96-3ca3-454f-b4bd-335ff5046c81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clases [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ],
      "source": [
        "# hay 20 clases correspondientes a los 20 grupos de noticias\n",
        "print(f'clases {np.unique(newsgroups_test.target)}')\n",
        "newsgroups_test.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXCICFSd_y90"
      },
      "source": [
        "## Similaridad de documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pki_olShnyE",
        "outputId": "8a17adc9-46cb-4d8a-b88a-f1c07525e307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THE WHITE HOUSE\n",
            "\n",
            "                  Office of the Press Secretary\n",
            "                   (Pittsburgh, Pennslyvania)\n",
            "______________________________________________________________\n",
            "For Immediate Release                         April 17, 1993     \n",
            "\n",
            "             \n",
            "                  RADIO ADDRESS TO THE NATION \n",
            "                        BY THE PRESIDENT\n",
            "             \n",
            "                Pittsburgh International Airport\n",
            "                    Pittsburgh, Pennsylvania\n",
            "             \n",
            "             \n",
            "10:06 A.M. EDT\n",
            "             \n",
            "             \n",
            "             THE PRESIDENT:  Good morning.  My voice is coming to\n",
            "you this morning through the facilities of the oldest radio\n",
            "station in America, KDKA in Pittsburgh.  I'm visiting the city to\n",
            "meet personally with citizens here to discuss my plans for jobs,\n",
            "health care and the economy.  But I wanted first to do my weekly\n",
            "broadcast with the American people. \n",
            "             \n",
            "             I'm told this station first broadcast in 1920 when\n",
            "it reported that year's presidential elections.  Over the past\n",
            "seven decades presidents have found ways to keep in touch with\n",
            "the people, from whistle-stop tours to fire-side chats to the bus\n",
            "tour that I adopted, along with Vice President Gore, in last\n",
            "year's campaign.\n",
            "             \n",
            "             Every Saturday morning I take this time to talk with\n",
            "you, my fellow Americans, about the problems on your minds and\n",
            "what I'm doing to try and solve them.  It's my way of reporting\n",
            "to you and of giving you a way to hold me accountable.\n",
            "             \n",
            "             You sent me to Washington to get our government and\n",
            "economy moving after years of paralysis and policy and a bad\n",
            "experiment with trickle-down economics.  You know how important\n",
            "it is for us to make bold, comprehensive changes in the way we do\n",
            "business.  \n",
            "             \n",
            "             We live in a competitive global economy.  Nations\n",
            "rise and fall on the skills of their workers, the competitiveness\n",
            "of their companies, the imagination of their industries, and the\n",
            "cooperative experience and spirit that exists between business,\n",
            "labor and government.  Although many of the economies of the\n",
            "industrialized world are now suffering from slow growth, they've\n",
            "made many of the smart investments and the tough choices which\n",
            "our government has for too long ignored.  That's why many of them\n",
            "have been moving ahead and too many of our people have been\n",
            "falling behind.\n",
            "             \n",
            "             We have an economy today that even when it grows is\n",
            "not producing new jobs.  We've increased the debt of our nation\n",
            "by four times over the last 12 years, and we don't have much to\n",
            "show for it.  We know that wages of most working people have\n",
            "stopped rising, that most people are working longer work weeks\n",
            "and that too many families can no longer afford the escalating\n",
            "cost of health care.\n",
            "             \n",
            "             But we also know that, given the right tools, the\n",
            "right incentives and the right encouragement, our workers and\n",
            "businesses can make the kinds of products and profits our economy\n",
            "needs to expand opportunity and to make our communities better\n",
            "places to live.\n",
            "             \n",
            "             In many critical products today Americans are the\n",
            "low cost, high quality producers.  Our task is to make sure that\n",
            "we create more of those kinds of jobs.\n",
            "             \n",
            "             Just two months ago I gave Congress my plan for\n",
            "long-term jobs and economic growth.  It changes the old\n",
            "priorities in Washington and puts our emphasis where it needs to\n",
            "be -- on people's real needs, on increasing investments and jobs\n",
            "and education, on cutting the federal deficit, on stopping the\n",
            "waste which pays no dividends, and redirecting our precious\n",
            "resources toward investment that creates jobs now and lays the\n",
            "groundwork for robust economic growth in the future.\n",
            "             \n",
            "             These new directions passed the Congress in record\n",
            "time and created a new sense of hope and opportunity in our\n",
            "country.  Then the jobs plan I presented to Congress, which would\n",
            "create hundreds of thousands of jobs, most of them in the private\n",
            "sector in 1993 and 1994, passed the House of Representatives.  It\n",
            "now has the support of a majority of the United States Senate. \n",
            "But it's been held up by a filibuster of a minority in the\n",
            "Senate, just 43 senators.  They blocked a vote that they know\n",
            "would result in the passage of our bill and the creation of jobs.\n",
            "             \n",
            "             The issue isn't politics; the issue is people. \n",
            "Millions of Americans are waiting for this legislation and\n",
            "counting on it, counting on us in Washington.  But the jobs bill\n",
            "has been grounded by gridlock.  \n",
            "             \n",
            "             I know the American people are tired of business as\n",
            "usual and politics as usual.  I know they don't want us to spin\n",
            "or wheels.  They want the recovery to get moving.  So I have\n",
            "taken a first step to break this gridlock and gone the extra\n",
            "mile.  Yesterday I offered to cut the size of this plan by 25\n",
            "percent -- from $16 billion to $12 billion.  \n",
            "             \n",
            "             It's not what I'd hoped for.  With 16 million\n",
            "Americans looking for full-time work, I simply can't let the bill\n",
            "languish when I know that even a compromise bill will mean\n",
            "hundreds of thousands of jobs for our people.  The mandate is to\n",
            "act to achieve change and move the country forward.  By taking\n",
            "this initiative in the face of an unrelenting Senate talkathon, I\n",
            "think we can respond to your mandate and achieve a significant\n",
            "portion of our original goals.\n",
            "             \n",
            "             First, we want to keep the programs as much as\n",
            "possible that are needed to generate jobs and meet human needs,\n",
            "including highway and road construction, summer jobs for young\n",
            "people, immunization for children, construction of waste water\n",
            "sites, and aid to small businesses.  We also want to keep funding\n",
            "for extended unemployment compensation benefits, for people who\n",
            "have been unemployed for a long time because the economy isn't\n",
            "creating jobs.\n",
            "             \n",
            "             Second, I've recommended that all the other programs\n",
            "in the bill be cut across-the-board by a little more than 40\n",
            "percent.\n",
            "             \n",
            "             And third, I've recommended a new element in this\n",
            "program to help us immediately start our attempt to fight against\n",
            "crime by providing $200 million for cities and towns to rehire\n",
            "police officers who lost their jobs during the recession and put\n",
            "them back to work protecting our people.  I'm also going to fight\n",
            "for a tough crime bill because the people of this country need it\n",
            "and deserve it.\n",
            "             \n",
            "             Now, the people who are filibustering this bill --\n",
            "the Republican senators -- say they won't vote for it because it\n",
            "increases deficit spending, because there's extra spending this\n",
            "year that hasn't already been approved.  That sounds reasonable,\n",
            "doesn't it?  Here's what they don't say.  This program is more\n",
            "than paid for by budget cuts over my five-year budget, and this\n",
            "budget is well within the spending limits already approved by the\n",
            "Congress this year.\n",
            "             \n",
            "             It's amazing to me that many of these same senators\n",
            "who are filibustering the bill voted during the previous\n",
            "administration for billions of dollars of the same kind of\n",
            "emergency spending, and much of it was not designed to put the\n",
            "American people to work.  \n",
            "             \n",
            "             This is not about deficit spending.  We have offered\n",
            "a plan to cut the deficit.  This is about where your priorities\n",
            "are -- on people or on politics.  \n",
            "             \n",
            "             Keep in mind that our jobs bill is paid for dollar\n",
            "for dollar.  It is paid for by budget cuts.  And it's the\n",
            "soundest investment we can now make for ourselves and our\n",
            "children.  I urge all Americans to take another look at this jobs\n",
            "and investment program; to consider again the benefits for all of\n",
            "us when we've helped make more American partners working to\n",
            "ensure the future of our nation and the strength of our economy.\n",
            "             \n",
            "             You know, if every American who wanted a job had\n",
            "one, we wouldn't have a lot of the other problems we have in this\n",
            "country today.  This bill is not a miracle, it's a modest first\n",
            "step to try to set off a job creation explosion in this country\n",
            "again.  But it's a step we ought to take.  And it is fully paid\n",
            "for over the life of our budget.\n",
            "             \n",
            "             Tell your lawmakers what you think.  Tell them how\n",
            "important the bill is.  If it passes, we'll all be winners.\n",
            "             \n",
            "             Good morning, and thank you for listening.\n"
          ]
        }
      ],
      "source": [
        "# Veamos similaridad de documentos. Tomemos algún documento\n",
        "idx = 4811\n",
        "print(newsgroups_train.data[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ssa9bqJ-hA_v"
      },
      "outputs": [],
      "source": [
        "# midamos la similaridad coseno con todos los documentos de train\n",
        "cossim = cosine_similarity(X_train[idx], X_train)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_mDA7p3AzcQ",
        "outputId": "9b6d24fc-c4a5-48b0-ce04-982fab677574"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.70930477, 0.67474953, ..., 0.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ],
      "source": [
        "# podemos ver los valores de similaridad ordenados de mayor a menos\n",
        "np.sort(cossim)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OIhDA1jAryX",
        "outputId": "9513fe56-0820-4b13-f420-dda8fdb61493"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4811,  6635,  4253, ...,  1534, 10055,  4750])"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ],
      "source": [
        "# y a qué documentos corresponden\n",
        "np.argsort(cossim)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hP7qLS4ZBLps"
      },
      "outputs": [],
      "source": [
        "# los 5 documentos más similares:\n",
        "mostsim = np.argsort(cossim)[::-1][1:6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QdJLHPJACvaj",
        "outputId": "1a64f76b-841a-4537-9661-02d5d4848747"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'talk.politics.misc'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 171
        }
      ],
      "source": [
        "# el documento original pertenece a la clase:\n",
        "newsgroups_train.target_names[y_train[idx]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWy_73epCbFG",
        "outputId": "9f3b7513-cd91-4e7f-b958-0138ea77a8f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n"
          ]
        }
      ],
      "source": [
        "# y los 5 más similares son de las clases:\n",
        "for i in mostsim:\n",
        "  print(newsgroups_train.target_names[y_train[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRoNnKwhBqzq"
      },
      "source": [
        "### Modelo de clasificación Naïve Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "TPM0thDaLk0R",
        "outputId": "889aa831-c0d6-4b24-d275-1f4f41a13690"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ],
      "source": [
        "# es muy fácil instanciar un modelo de clasificación Naïve Bayes y entrenarlo con sklearn\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrQjzM48Mu4T"
      },
      "outputs": [],
      "source": [
        "# con nuestro vectorizador ya fiteado en train, vectorizamos los textos\n",
        "# del conjunto de test\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_test = newsgroups_test.target\n",
        "y_pred =  clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkGJhetEPdA4",
        "outputId": "a7dad999-efca-4267-cf75-a66512275460"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5854345727938506"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ],
      "source": [
        "# el F1-score es una metrica adecuada para reportar desempeño de modelos de claificación\n",
        "# es robusta al desbalance de clases. El promediado 'macro' es el promedio de los\n",
        "# F1-score de cada clase. El promedio 'micro' es equivalente a la accuracy que no\n",
        "# es una buena métrica cuando los datasets son desbalanceados\n",
        "f1_score(y_test, y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McArD4rSDR2K"
      },
      "source": [
        "### Consigna del desafío 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJgf6GQIIEH1"
      },
      "source": [
        "**1**. Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos.\n",
        "Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido\n",
        "la similaridad según el contenido del texto y la etiqueta de clasificación.\n",
        "\n",
        "**2**. Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación\n",
        "(f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros\n",
        "de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial\n",
        "y ComplementNB.\n",
        "\n",
        "**3**. Transponer la matriz documento-término. De esa manera se obtiene una matriz\n",
        "término-documento que puede ser interpretada como una colección de vectorización de palabras.\n",
        "Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares. **La elección de palabras no debe ser al azar para evitar la aparición de términos poco interpretables, elegirlas \"manualmente\"**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Estudiar similaridad del coseno"
      ],
      "metadata": {
        "id": "TdWdsXDOXJoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_similaridad(idx):\n",
        "  j = 0\n",
        "  print(f'Para el documento N°: {idx}\\nDocumento:\\n')\n",
        "  print(newsgroups_train.data[idx])\n",
        "  # midamos la similaridad coseno con todos los documentos de train\n",
        "  cossim = cosine_similarity(X_train[idx], X_train)[0]\n",
        "  # visualicemos cuales son los valores mas parecidos\n",
        "  print(f'\\n\\n--------------------------------------------')\n",
        "  print(f'Los documentos mas cercanos tienen una similaridad de:')\n",
        "  print(np.sort(cossim)[::-1][1:6])\n",
        "  mostsim = np.argsort(cossim)[::-1][1:6]\n",
        "  # el documento original\n",
        "  orig_class = newsgroups_train.target_names[y_train[idx]]\n",
        "  print(f'\\nEl documento evaluado pertenece a la clase: {orig_class}\\n')\n",
        "  # y los 5 más similares son de las clases:\n",
        "  for i in mostsim:\n",
        "    sim_class = newsgroups_train.target_names[y_train[i]]\n",
        "    print(f'Los 5 documentos mas similares pertenecen a la clases: {sim_class}')\n",
        "    if sim_class == orig_class:\n",
        "      j+=1\n",
        "  print(f'\\nDe los 5 documentos, {j} son de la misma clase que el original')"
      ],
      "metadata": {
        "id": "pjTfFtSNaKaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_similaridad(852)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwm54etLb3OZ",
        "outputId": "1b76c6fa-12ab-46a1-8426-b59ce933997c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Para el documento N°: 852\n",
            "Documento:\n",
            "\n",
            ":P\n",
            ":P>My favorite reply to the \"you are being too literal-minded\" complaint is\n",
            ":P>that if the bible is really inspired by God and if it is really THAT\n",
            ":P>important to him, then he would make damn certain all the translators and\n",
            ":P>scribes and people interpreting and copying it were getting it right,\n",
            ":P>literally.  If not, then why should I put ANY merit at all in something\n",
            ":P>that has been corrupted over and over and over by man even if it was\n",
            ":P>originally inspired by God?\n",
            ":P\n",
            ":PThe \"corrupted over and over\" theory is pretty weak.  Comparison of the\n",
            ":Pcurrent hebrew text with old versions and translations shows that the text\n",
            ":Phas in fact changed very little over a space of some two millennia.  This\n",
            ":Pshouldn't be all that suprising; people who believe in a text in this manner\n",
            ":Pare likely to makes some pains to make good copies.\n",
            "\n",
            "\n",
            "--------------------------------------------\n",
            "Los documentos mas cercanos tienen una similaridad de:\n",
            "[0.47556128 0.29199601 0.27296889 0.26666532 0.25742023]\n",
            "\n",
            "El documento evaluado pertenece a la clase: alt.atheism\n",
            "\n",
            "Los 5 documentos mas similares pertenecen a la clases: alt.atheism\n",
            "Los 5 documentos mas similares pertenecen a la clases: soc.religion.christian\n",
            "Los 5 documentos mas similares pertenecen a la clases: alt.atheism\n",
            "Los 5 documentos mas similares pertenecen a la clases: talk.politics.mideast\n",
            "Los 5 documentos mas similares pertenecen a la clases: talk.religion.misc\n",
            "\n",
            "De los 5 documentos, 2 son de la misma clase que el original\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_similaridad(1583)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK6Lem9Yeasx",
        "outputId": "31c48b13-95aa-4bb6-d723-68c70ad7dac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Para el documento N°: 1583\n",
            "Documento:\n",
            "\n",
            "Found it! Thanks. I got several offers for help. I appreciate it and\n",
            "will be contacting those people via e-mail.\n",
            "\n",
            "Thanks again...\n",
            "\n",
            "\n",
            "--------------------------------------------\n",
            "Los documentos mas cercanos tienen una similaridad de:\n",
            "[0.2859492  0.23523338 0.21219821 0.19131326 0.18752988]\n",
            "\n",
            "El documento evaluado pertenece a la clase: sci.space\n",
            "\n",
            "Los 5 documentos mas similares pertenecen a la clases: comp.graphics\n",
            "Los 5 documentos mas similares pertenecen a la clases: comp.windows.x\n",
            "Los 5 documentos mas similares pertenecen a la clases: rec.sport.baseball\n",
            "Los 5 documentos mas similares pertenecen a la clases: misc.forsale\n",
            "Los 5 documentos mas similares pertenecen a la clases: sci.space\n",
            "\n",
            "De los 5 documentos, 1 son de la misma clase que el original\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_similaridad(343)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dnn-qrs6e4jO",
        "outputId": "6ef21ca9-e064-4dbb-91f0-ae4c067d111e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Para el documento N°: 343\n",
            "Documento:\n",
            "\n",
            "\n",
            "In fact, you probably want to avoid US Government anything for such a\n",
            "project.  The pricetag is invariably too high, either in money or in\n",
            "hassles.\n",
            "\n",
            "The important thing to realize here is that the big cost of getting to\n",
            "the Moon is getting into low Earth orbit.  Everything else is practically\n",
            "down in the noise.  The only part of getting to the Moon that poses any\n",
            "new problems, beyond what you face in low orbit, is the last 10km --\n",
            "the actual landing -- and that is not immensely difficult.  Of course,\n",
            "you *can* spend sagadollars (saga- is the metric prefix for beelyuns\n",
            "and beelyuns) on things other than the launches, but you don't have to.\n",
            "\n",
            "The major component of any realistic plan to go to the Moon cheaply (for\n",
            "more than a brief visit, at least) is low-cost transport to Earth orbit.\n",
            "For what it costs to launch one Shuttle or two Titan IVs, you can develop\n",
            "a new launch system that will be considerably cheaper.  (Delta Clipper\n",
            "might be a bit more expensive than this, perhaps, but there are less\n",
            "ambitious ways of bringing costs down quite a bit.)  Any plan for doing\n",
            "sustained lunar exploration using existing launch systems is wasting\n",
            "money in a big way.\n",
            "\n",
            "Given this, questions like whose launch facilities you use are *not* a\n",
            "minor detail; they are very important to the cost of the launches, which\n",
            "dominates the cost of the project.\n",
            "\n",
            "\n",
            "--------------------------------------------\n",
            "Los documentos mas cercanos tienen una similaridad de:\n",
            "[0.35981154 0.34888854 0.31049181 0.30079404 0.29237871]\n",
            "\n",
            "El documento evaluado pertenece a la clase: sci.space\n",
            "\n",
            "Los 5 documentos mas similares pertenecen a la clases: sci.space\n",
            "Los 5 documentos mas similares pertenecen a la clases: sci.space\n",
            "Los 5 documentos mas similares pertenecen a la clases: sci.space\n",
            "Los 5 documentos mas similares pertenecen a la clases: sci.space\n",
            "Los 5 documentos mas similares pertenecen a la clases: sci.crypt\n",
            "\n",
            "De los 5 documentos, 4 son de la misma clase que el original\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_similaridad(2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQqqvsjNfD1O",
        "outputId": "ba0edb31-bde0-418c-be81-48eea97e3d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Para el documento N°: 2000\n",
            "Documento:\n",
            "\n",
            "\n",
            "\n",
            "_Cycle World_ puts one out, but I'm sure it's not very objective.  Try talking\n",
            "with dealers and the people that hang out there, as well as us.  We love to\n",
            "give advice.\n",
            "\n",
            "\n",
            "Most of the bigger banks have a blue book which includes motos -- ask for the\n",
            "one with RVs in it.\n",
            "\n",
            "\n",
            "Couldn't help you here.\n",
            "\n",
            "\n",
            "You're reading it.\n",
            "\n",
            "----------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "--------------------------------------------\n",
            "Los documentos mas cercanos tienen una similaridad de:\n",
            "[0.22168372 0.22043832 0.20057127 0.19569925 0.19561147]\n",
            "\n",
            "El documento evaluado pertenece a la clase: rec.motorcycles\n",
            "\n",
            "Los 5 documentos mas similares pertenecen a la clases: talk.politics.misc\n",
            "Los 5 documentos mas similares pertenecen a la clases: talk.politics.mideast\n",
            "Los 5 documentos mas similares pertenecen a la clases: talk.politics.misc\n",
            "Los 5 documentos mas similares pertenecen a la clases: talk.politics.misc\n",
            "Los 5 documentos mas similares pertenecen a la clases: talk.religion.misc\n",
            "\n",
            "De los 5 documentos, 0 son de la misma clase que el original\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_similaridad(10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl_KI4tJfSeI",
        "outputId": "2a86f51e-6d36-4fc2-c15f-b1d3a1dd34ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Para el documento N°: 10000\n",
            "Documento:\n",
            "\n",
            "I have to disagree with this.  I have a 92 Z28 with a 350 and a 4-speed auto\n",
            "w/ overdrive, and it is really better that way.  Chevy autos are reknowned\n",
            "for their long life and ability to handle copious amount of power.  I live \n",
            "in the Dallas area, and a manual would be much harder to drive in the traffic \n",
            "here.  Now if I still lived out in the sticks like I used to, a manual would be\n",
            "more fun.  \n",
            "\n",
            "Safety-wise, an auto is less distracting...I would hate to have to be    \n",
            "shifting gears while I was trying to ease into traffic in the freeways here.\n",
            "Performance-wise, I can hold my own against any stock 5.0 Mustang or 5.0\n",
            "Camaro w/ a five speed.  \n",
            "\n",
            "All of this IMHO... :)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------\n",
            "Los documentos mas cercanos tienen una similaridad de:\n",
            "[0.2612887  0.2553084  0.23345549 0.21737891 0.21498468]\n",
            "\n",
            "El documento evaluado pertenece a la clase: rec.autos\n",
            "\n",
            "Los 5 documentos mas similares pertenecen a la clases: rec.autos\n",
            "Los 5 documentos mas similares pertenecen a la clases: rec.autos\n",
            "Los 5 documentos mas similares pertenecen a la clases: talk.politics.guns\n",
            "Los 5 documentos mas similares pertenecen a la clases: rec.autos\n",
            "Los 5 documentos mas similares pertenecen a la clases: sci.electronics\n",
            "\n",
            "De los 5 documentos, 3 son de la misma clase que el original\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_similaridad(674)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDoUB6brfhg7",
        "outputId": "ac298f15-0909-49b6-97f5-ed90f90f8c4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Para el documento N°: 674\n",
            "Documento:\n",
            "\n",
            "From: Center for Policy Research <cpr>\n",
            "Subject: Assistance to Palest.people\n",
            "\n",
            "\n",
            "U.N. General Assembly Resolution 46/201 of 20 December 1991\n",
            "\n",
            "ASSISTANCE TO THE PALESTINIAN PEOPLE\n",
            "---------------------------------------------\n",
            "The General Assembly\n",
            "\n",
            "Recalling its resolution 45/183 of 21 December 1990\n",
            "\n",
            "Taking into account the intifadah of the Palestinian people in the\n",
            "occupied Palestinian territory against the Israeli occupation,\n",
            "including Israeli economic and social policies and practices,\n",
            "\n",
            "Rejecting Israeli restrictions on external economic and social\n",
            "assistance to the Palestinian people in the occupied Palestinian\n",
            "territory,\n",
            "\n",
            "Concerned about the economic losses of the Palestinian people as a\n",
            "result of the Gulf crisis,\n",
            "\n",
            "Aware of the increasing need to provide economic and social\n",
            "assistance to the Palestinian people,\n",
            "\n",
            "Affirming that the Palestinian people cannot develop their\n",
            "national economy as long as the Israeli occupation persists,\n",
            "\n",
            "1. Takes note of the report of the Secretary-General on assistance\n",
            "to the Palestinian people;\n",
            "\n",
            "2. Expresses its appreciation to the States, United Nations bodies\n",
            "and intergovernmental and non-governmental organizations that have\n",
            "provided assistance to the Palestinian people,\n",
            "\n",
            "3. Requests the international community, the United Nations system\n",
            "and intergovernmental and non-governmental organizations to\n",
            "sustain and increase their assistance to the Palestinian people,\n",
            "in close cooperation with the Palestine Liberation Organization\n",
            "(PLO), taking in account the economic losses of the Palestinian\n",
            "people as a result of the Gulf crisis;\n",
            "\n",
            "4. Calls for treatment on a transit basis of Palestinian exports\n",
            "and imports passing through neighbouring ports and points of exit\n",
            "and entry;\n",
            "\n",
            "5. Also calls for the granting of trade concessions and concrete\n",
            "preferential measures for Palestinian exports on the basis of\n",
            "Palestinian certificates of origin;\n",
            "\n",
            "6. Further calls for the immediate lifting of Israeli restrictions\n",
            "and obstacles hindering the implementation of assistance projects\n",
            "by the United Nations Development Programme, other United Nations\n",
            "bodies and others providing economic and social assistance to the\n",
            "Palestinian people in the occupied Palestinian territory;\n",
            "\n",
            "7. Reiterates its call for the implementation of development\n",
            "projects in the occupied Palestinian territory, including the\n",
            "projects mentioned in its resolution 39/223 of 18 December 1984;\n",
            "\n",
            "8. Calls for facilitation of the establishment of Palestinian\n",
            "development banks in the occupied Palestinian territory, with a\n",
            "view to promoting investment, production, employment and income\n",
            "therein;\n",
            "\n",
            "9. Requests the Secretary-General to report to the General\n",
            "The General Assembly at its 47th session, through the Economic and Social\n",
            "Council, on the progress made in the implementation of the present\n",
            "resolution.\n",
            "-----------------------------------------------\n",
            "\n",
            "\n",
            "--------------------------------------------\n",
            "Los documentos mas cercanos tienen una similaridad de:\n",
            "[0.37783262 0.30072232 0.28905809 0.27014472 0.26923338]\n",
            "\n",
            "El documento evaluado pertenece a la clase: talk.politics.mideast\n",
            "\n",
            "Los 5 documentos mas similares pertenecen a la clases: talk.politics.mideast\n",
            "Los 5 documentos mas similares pertenecen a la clases: talk.politics.mideast\n",
            "Los 5 documentos mas similares pertenecen a la clases: talk.politics.mideast\n",
            "Los 5 documentos mas similares pertenecen a la clases: talk.politics.mideast\n",
            "Los 5 documentos mas similares pertenecen a la clases: talk.politics.mideast\n",
            "\n",
            "De los 5 documentos, 5 son de la misma clase que el original\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Analisis de resultados"
      ],
      "metadata": {
        "id": "2sE46KlJzgu2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "Según los resultados obtenidos, podemos resumir lo siguiente:\n",
        "\n",
        "doc evaluado     doc de la misma clase (extraidos del top 5 mas similes)\n",
        "    852                  2\n",
        "    1583                 1\n",
        "    343                  4\n",
        "    2000                 0\n",
        "    10000                3\n",
        "    674                  5\n",
        "\n",
        "\n",
        "Según esto podemos ver que ciertamente la similaridad del coseno logra ubicar documentos similes y\n",
        "que tiene cierta acertividad, evidentemente dependerá de cuan nutrido es el documento en palabras\n",
        "ya que se basa en esto directamente, por lo que podemos decir que dependerá mucho de el documento\n",
        "y el corpus como tal para poder tener buenos resultados.\n",
        "\n",
        "Sin embargo, tomando en cuenta que es un análisis no tan demandante en cuanto a computo, no tan\n",
        "\"inteligente\" y que se usa solo una propiedad de geometria analitica, resulta interesante que\n",
        "tenga buenos resultados.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "OALfXfTN2Cun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Entrenar modelos y realizar tunnig de NB y ComplementNB\n"
      ],
      "metadata": {
        "id": "mylI_XYhIEwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# 20newsgroups por ser un dataset clásico de NLP ya viene incluido y formateado\n",
        "# en sklearn\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "0SZTfIZ-IWEz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
      ],
      "metadata": {
        "id": "PmZRn38tIXBA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modelo MultinomialNB base"
      ],
      "metadata": {
        "id": "hoR1qNZV3kGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidfvect = TfidfVectorizer()\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "y_train = newsgroups_train.target\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_test = newsgroups_test.target\n",
        "y_pred =  clf.predict(X_test)\n",
        "f1_score(y_test, y_pred, average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCfN5OzJ3cIm",
        "outputId": "44f3411d-5427-4512-e166-a25e2f764ef9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5854345727938506"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modelo MultinomialNB optimizado"
      ],
      "metadata": {
        "id": "Vwdf_SEr3pK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidfvect = TfidfVectorizer(lowercase=True, norm= \"l2\", sublinear_tf = False, max_df=0.1, min_df=1)\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "y_train = newsgroups_train.target"
      ],
      "metadata": {
        "id": "4a-OnxRgYAJL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MultinomialNB(alpha=0.01)\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "OSCIh7zkJIjc",
        "outputId": "46b50660-65f4-4a85-b533-38183d69e033"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.01)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.01)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_test = newsgroups_test.target\n",
        "y_pred =  clf.predict(X_test)"
      ],
      "metadata": {
        "id": "qRATdIykOunw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_test, y_pred, average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDCDydDUOzpo",
        "outputId": "7cc04d86-af33-4dbc-e436-9fd81320fb94"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.685572214627961"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modelo ComplementNB base"
      ],
      "metadata": {
        "id": "4PtSy2PL32p2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidfvect_c = TfidfVectorizer()\n",
        "X_train_c = tfidfvect_c.fit_transform(newsgroups_train.data)\n",
        "y_train_c = newsgroups_train.target\n",
        "clf_comp = ComplementNB()\n",
        "clf_comp.fit(X_train_c, y_train_c)\n",
        "X_test_c = tfidfvect_c.transform(newsgroups_test.data)\n",
        "y_test_c = newsgroups_test.target\n",
        "y_pred_c =  clf_comp.predict(X_test_c)\n",
        "f1_score(y_test_c, y_pred_c, average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YM8JWuG4FEK",
        "outputId": "14d0ab7e-09fb-4158-8a49-52b8a10fd9b5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.692953349950875"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modelo ComplementNB optimizado"
      ],
      "metadata": {
        "id": "a8khPi324XDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidfvect = TfidfVectorizer(lowercase=True, norm= \"l2\", sublinear_tf = False, max_df=0.15, min_df=1)\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "y_train = newsgroups_train.target"
      ],
      "metadata": {
        "id": "Ha3sdw1dafqK"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_comp = ComplementNB(alpha=0.305)\n",
        "clf_comp.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "pdpl08VGRtB3",
        "outputId": "b1db0e29-3ed9-4def-d41f-30a20124d9d2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ComplementNB(alpha=0.305)"
            ],
            "text/html": [
              "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ComplementNB(alpha=0.305)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ComplementNB</label><div class=\"sk-toggleable__content\"><pre>ComplementNB(alpha=0.305)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_test = newsgroups_test.target\n",
        "y_pred =  clf_comp.predict(X_test)"
      ],
      "metadata": {
        "id": "uz1tosEmSH4P"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_test, y_pred, average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzYeOKNuSL_q",
        "outputId": "59f0bfa1-c936-4a0f-9b78-45d3458480e5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7002244870750653"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Analisis de resultados"
      ],
      "metadata": {
        "id": "nHg1itq95Z7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Según los resultados obtenidos, podemos observar que el modelo MultinomialNB pudo ser optimizado su\n",
        "F1 Score desde 0,58 a 0,68 lo cual es una mejoría notoria, en donde los parámetros más\n",
        "incidentes fueron max_df (en el vectorizador TfidfVectorizer) y alpha del modelo MultinomialNB.\n",
        "\n",
        "Por otra parte el modelo ComplementNB, hace un análisis tomando en cuenta las estadísticas del\n",
        "complemento de cada clase para el cálculo de los pesos del modelo, lo que hace que sea mas estable\n",
        "sobretodo en datasets desbalanceados, déspues de varias pruebas solo se pudo mejorar su resultado\n",
        "F1 Score desde 0.6929 a 0.7002\n",
        "```"
      ],
      "metadata": {
        "id": "5tcCp8vM5mcE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Evaluar matriz termino-documento"
      ],
      "metadata": {
        "id": "1xo07IWDYliX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# 20newsgroups por ser un dataset clásico de NLP ya viene incluido y formateado\n",
        "# en sklearn\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "v1AyBtxKYwCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cargamos los datos (ya separados de forma predeterminada en train y test)\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
      ],
      "metadata": {
        "id": "7QEfOPOeY1HX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidfvect = TfidfVectorizer(max_df=0.1)"
      ],
      "metadata": {
        "id": "nwbARMmWZjuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)"
      ],
      "metadata": {
        "id": "7QMi_7WwZ9Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_transpuesta = X_train.T\n",
        "\n",
        "idx2word = {v: k for k,v in tfidfvect.vocabulary_.items()}"
      ],
      "metadata": {
        "id": "1Sm30Q_Xaxbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_simil_td(idx):\n",
        "\n",
        "  print(f'El termino a evaluar es: {idx2word[idx]}\\n')\n",
        "  # midamos la similaridad coseno con todos los documentos de train\n",
        "  cossim = cosine_similarity(X_transpuesta[idx], X_transpuesta)[0]\n",
        "  # visualicemos cuales son los valores mas parecidos\n",
        "  print(f'Los 5 terminos mas cercanos tienen una similaridad de:')\n",
        "  print(np.sort(cossim)[::-1][1:6])\n",
        "  mostsim = np.argsort(cossim)[::-1][1:6]\n",
        "  # y los 5 más similares:\n",
        "  print(f'\\nLos 5 terminos mas cercanos segun la similaridad de coseno son:\\n')\n",
        "  for i in mostsim:\n",
        "    sim_class = idx2word[i]\n",
        "    print(f'{sim_class}')"
      ],
      "metadata": {
        "id": "IAZ83XurnQ6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_simil_td(35179)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3ik7RkbpygY",
        "outputId": "52d8e2f0-139e-4205-bc7f-bfa76bf734fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El termino a evaluar es: drugs\n",
            "\n",
            "Los 5 terminos mas cercanos tienen una similaridad de:\n",
            "[0.36328859 0.36328859 0.31883096 0.28219986 0.28219986]\n",
            "\n",
            "Los 5 terminos mas cercanos segun la similaridad de coseno son:\n",
            "\n",
            "amphetamines\n",
            "chg\n",
            "drug\n",
            "hazzards\n",
            "incarcerating\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_simil_td(56630)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GCIvulrwATD",
        "outputId": "bbeb0ab3-263f-4b40-faa9-005b400e9e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El termino a evaluar es: life\n",
            "\n",
            "Los 5 terminos mas cercanos tienen una similaridad de:\n",
            "[0.15243419 0.14483868 0.1403533  0.13973247 0.13949106]\n",
            "\n",
            "Los 5 terminos mas cercanos segun la similaridad de coseno son:\n",
            "\n",
            "real\n",
            "god\n",
            "sex\n",
            "eternal\n",
            "hermite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_simil_td(97140)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUtQybs5wGJm",
        "outputId": "c9ee402e-a8be-4533-d385-50116ce2c0d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El termino a evaluar es: work\n",
            "\n",
            "Los 5 terminos mas cercanos tienen una similaridad de:\n",
            "[0.14427037 0.14088067 0.13577355 0.13117565 0.11916676]\n",
            "\n",
            "Los 5 terminos mas cercanos segun la similaridad de coseno son:\n",
            "\n",
            "fine\n",
            "spoofing\n",
            "needed\n",
            "retraining\n",
            "installed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_simil_td(50776)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aoa3pnaGwSJ4",
        "outputId": "182ee617-327c-4e42-e94f-43ae3bf59e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El termino a evaluar es: investment\n",
            "\n",
            "Los 5 terminos mas cercanos tienen una similaridad de:\n",
            "[0.51425397 0.46401318 0.44305247 0.36274371 0.34813519]\n",
            "\n",
            "Los 5 terminos mas cercanos segun la similaridad de coseno son:\n",
            "\n",
            "benfits\n",
            "taxpayer\n",
            "settling\n",
            "resounding\n",
            "proxy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_simil_td(36942)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0AkEf0yw4p5",
        "outputId": "d58e5aea-cf41-448d-90f4-e6444bef162d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El termino a evaluar es: emergency\n",
            "\n",
            "Los 5 terminos mas cercanos tienen una similaridad de:\n",
            "[0.39004987 0.3336042  0.32132347 0.3144143  0.3048889 ]\n",
            "\n",
            "Los 5 terminos mas cercanos segun la similaridad de coseno son:\n",
            "\n",
            "receptionist\n",
            "clinic\n",
            "tac\n",
            "vor\n",
            "hospitalization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Analisis de resultados"
      ],
      "metadata": {
        "id": "l-Swy_kz8E4L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Según los resultados obtenidos, podemos observar que en este caso evaluando la matriz\n",
        "término-documento, la similaridad del coseno sigue ubicando cierta relación entre\n",
        "términos que tienen un documentos similares, una vez más, es interesante que pueda\n",
        "conseguir ciertas similitudes aunque sin ser prometedoras, pueden tomarse en cuenta\n",
        "quizás como un dato base para después de esto ir usando métodos más elaborados.\n",
        "```"
      ],
      "metadata": {
        "id": "BvKLSCAM8GQ8"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hoR1qNZV3kGM"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}